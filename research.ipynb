{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1dyDslJcwYoQmt47qcHuUUpcuxTG2jsiK",
      "authorship_tag": "ABX9TyP6wtzIr0CMqWM02MDdTsjd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chalakajaniththa/data/blob/main/research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "-itnEjlwcSTj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ErF6zQYjZtp-"
      },
      "outputs": [],
      "source": [
        "#read csv file and create dataframe\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/research/dataset/modified-sentence.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows where the Language is either \"Sin-Eng\" or \"Mixed\"\n",
        "filtered_df = df[df['Language'].isin(['Sin-Eng', 'Mixed'])]\n",
        "\n",
        "# Select the \"Sentence\" and \"Sentiment\" columns from the filtered DataFrame\n",
        "selected_columns = filtered_df[[\"Sentence\", \"Sentiment\"]]\n",
        "\n",
        "# Display the selected columns\n",
        "print(selected_columns)\n"
      ],
      "metadata": {
        "id": "DlEU7WBmceyk",
        "outputId": "7a46653b-5952-4c08-e877-8ba0c6639ee4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Sentence Sentiment\n",
            "0           Ammage Adarayta‚ù§Ô∏èEka Dawasak Madi Neda‚ù§Ô∏èüôè‚ù§Ô∏è  Negative\n",
            "3     chandimal.. uuu thama mulu tem ekama kaaa gaha...  Positive\n",
            "5               Lebsack 49k dammama eka dawasak wath be  Negative\n",
            "6     eth anith kattiya sathiyak withara online inna...   Neutral\n",
            "7                           meka salli kanawane...ai e?  Negative\n",
            "...                                                 ...       ...\n",
            "9586  why, how and when did you put a expiry date fo...  Negative\n",
            "9593                                Gerhold nam jarawak  Negative\n",
            "9594  Me mase web family plus packge eke total eka 6...   Neutral\n",
            "9595        munge Dan data kapana widiye awulk thiyenwa  Negative\n",
            "9598    Signal ne ne anee. Ekata mokak hari karannakoo.  Negative\n",
            "\n",
            "[4579 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Separate the DataFrame into classes based on 'Sentiment'\n",
        "positive_class = selected_columns[selected_columns['Sentiment'] == 'Positive']\n",
        "negative_class = selected_columns[selected_columns['Sentiment'] == 'Negative']\n",
        "neutral_class = selected_columns[selected_columns['Sentiment'] == 'Neutral']\n",
        "conflict_class = selected_columns[selected_columns['Sentiment'] == 'Conflict']\n",
        "\n",
        "# Determine the class with the maximum number of samples\n",
        "max_samples = max(len(positive_class), len(negative_class), len(neutral_class), len(conflict_class))\n",
        "\n",
        "# Up-sample the classes with fewer samples\n",
        "positive_upsampled = resample(positive_class, replace=True, n_samples=max_samples, random_state=42)\n",
        "negative_upsampled = resample(negative_class, replace=True, n_samples=max_samples, random_state=42)\n",
        "neutral_upsampled = resample(neutral_class, replace=True, n_samples=max_samples, random_state=42)\n",
        "conflict_upsampled = resample(conflict_class, replace=True, n_samples=max_samples, random_state=42)\n",
        "\n",
        "# Combine the up-sampled classes into a balanced DataFrame\n",
        "balanced_df = pd.concat([positive_upsampled, negative_upsampled, neutral_upsampled, conflict_upsampled])\n",
        "\n",
        "# Display the balanced DataFrame\n",
        "print(balanced_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp9QQ6D1wzzR",
        "outputId": "bd6841c2-171a-4562-d51a-c2f964c370a8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Sentence Sentiment\n",
            "2162                                Call time ehma mru.  Positive\n",
            "9568                  Thank you 6GB bonus ekak dunnata.  Positive\n",
            "6701                                   Gerhold niyamai.  Positive\n",
            "2234                                      Sathutui üòÉüòÉüòÉüòÉ  Positive\n",
            "1460  FB Messenger is actually one of the best messa...  Positive\n",
            "...                                                 ...       ...\n",
            "4843  Hodai habai signal na miss call gahala salli k...  Conflict\n",
            "569                    Signal ne..nthnm Hilpert hodaiüò≠üò≠  Conflict\n",
            "301                    Bartell walada wada hida Lebsack  Conflict\n",
            "1098  apit kemati Gerhold pawichchi karanna et signa...  Conflict\n",
            "1680  eka thama hodama eth time base yaddi connecrio...  Conflict\n",
            "\n",
            "[11348 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of samples for each sentiment class in the balanced DataFrame\n",
        "class_counts = balanced_df['Sentiment'].value_counts()\n",
        "\n",
        "# Display the class counts\n",
        "print(class_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XruuxmBDyiLO",
        "outputId": "dbd0f6f4-ab77-40c1-806f-d99f83af00ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive    2837\n",
            "Negative    2837\n",
            "Neutral     2837\n",
            "Conflict    2837\n",
            "Name: Sentiment, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Assuming balanced_df is your balanced DataFrame with \"Sentence\" and \"Sentiment\" columns\n",
        "X = balanced_df['Sentence']\n",
        "y = balanced_df['Sentiment']\n",
        "\n",
        "# Convert string labels to integer labels using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_sequences = tokenizer.texts_to_sequences(X)\n",
        "X_padded = pad_sequences(X_sequences)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and compile the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=X_padded.shape[1]))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(4, activation='softmax'))  # Assuming 4 classes (Positive, Negative, Neutral, Conflict)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH0QaESOy2Fp",
        "outputId": "e1736330-196d-4099-91bd-0959ee7d9253"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "227/227 [==============================] - 26s 102ms/step - loss: 0.7270 - accuracy: 0.6815 - val_loss: 0.2785 - val_accuracy: 0.9080\n",
            "Epoch 2/5\n",
            "227/227 [==============================] - 9s 41ms/step - loss: 0.1488 - accuracy: 0.9489 - val_loss: 0.1749 - val_accuracy: 0.9427\n",
            "Epoch 3/5\n",
            "227/227 [==============================] - 4s 19ms/step - loss: 0.0472 - accuracy: 0.9869 - val_loss: 0.1518 - val_accuracy: 0.9499\n",
            "Epoch 4/5\n",
            "227/227 [==============================] - 5s 22ms/step - loss: 0.0205 - accuracy: 0.9944 - val_loss: 0.1727 - val_accuracy: 0.9565\n",
            "Epoch 5/5\n",
            "227/227 [==============================] - 4s 18ms/step - loss: 0.0107 - accuracy: 0.9975 - val_loss: 0.1775 - val_accuracy: 0.9526\n",
            "71/71 [==============================] - 0s 6ms/step - loss: 0.2299 - accuracy: 0.9414\n",
            "Accuracy: 94.14%\n"
          ]
        }
      ]
    }
  ]
}